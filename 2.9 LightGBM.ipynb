{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ponnayo danne kellek aduwa gaman laga inna kol...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ape harak samjeta eka honda adrshyak</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tpita pisuda yako man htuwe atta kiyala aiyo</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kimbak eduwoth ape untath amma thaththawath pe...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lisan nathawa yanna puluwan yako api dannawa o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_hate\n",
       "0  ponnayo danne kellek aduwa gaman laga inna kol...     True\n",
       "1               ape harak samjeta eka honda adrshyak    False\n",
       "2       tpita pisuda yako man htuwe atta kiyala aiyo    False\n",
       "3  kimbak eduwoth ape untath amma thaththawath pe...     True\n",
       "4  lisan nathawa yanna puluwan yako api dannawa o...    False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "column_names = [\"text\", \"is_hate\"]\n",
    "\n",
    "df = pd.read_csv('1.preprocessed_data.csv', on_bad_lines='skip', sep=\",\", encoding='iso-8859-1', header=0, names=column_names)\n",
    "df['is_hate'] = df['is_hate'].astype(bool)\n",
    "df['text'] = df['text'].astype('str')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 721, number of negative: 1043\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1352\n",
      "[LightGBM] [Info] Number of data points in the train set: 1764, number of used features: 97\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.408730 -> initscore=-0.369217\n",
      "[LightGBM] [Info] Start training from score -0.369217\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "No early stopping, used all iterations\n",
      "0.7074829931972789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.88      0.78       260\n",
      "        True       0.73      0.46      0.56       181\n",
      "\n",
      "    accuracy                           0.71       441\n",
      "   macro avg       0.71      0.67      0.67       441\n",
      "weighted avg       0.71      0.71      0.69       441\n",
      "\n",
      "Hate\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. Data Preprocessing\n",
    "# Using TfidfVectorizer to convert text data into numerical format\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)  # you can adjust the number of features\n",
    "X = tfidf_vectorizer.fit_transform(df['text'])\n",
    "y = df['is_hate']\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Model Training\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_error',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "num_round = 100\n",
    "# bst = lgb.train(params, train_data, num_round, valid_sets=[val_data], early_stopping_rounds=10)\n",
    "# bst = lgb.train(params, train_data, num_round, valid_sets=[val_data], early_stopping_rounds=10, verbose_eval=10)\n",
    "evals_result = {}  # to store results of the training process\n",
    "\n",
    "bst = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_round,\n",
    "    valid_sets=[val_data]\n",
    ")\n",
    "\n",
    "# To implement early stopping, we check the results\n",
    "best_round = bst.best_iteration\n",
    "if best_round:\n",
    "    print(f\"Early stopping at round {best_round}\")\n",
    "else:\n",
    "    print(\"No early stopping, used all iterations\")\n",
    "\n",
    "\n",
    "# 3. Evaluation\n",
    "y_pred = bst.predict(X_val, num_iteration=bst.best_iteration)\n",
    "y_pred_binary = np.round(y_pred)\n",
    "\n",
    "print(accuracy_score(y_val, y_pred_binary))\n",
    "report = classification_report(y_val, y_pred_binary)\n",
    "print(report)\n",
    "\n",
    "# 4. Prediction\n",
    "def predict_hate(text):\n",
    "    transformed_text = tfidf_vectorizer.transform([text])\n",
    "    prediction = bst.predict(transformed_text, num_iteration=bst.best_iteration)\n",
    "    return \"Hate\" if np.round(prediction)[0] else \"Not Hate\"\n",
    "\n",
    "# Test the prediction function\n",
    "print(predict_hate(\"kalakanni deshapaluwo\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hate\n"
     ]
    }
   ],
   "source": [
    "# Test the prediction function\n",
    "print(predict_hate(\"kalakanni deshapaluwo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# values for confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred_binary)\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # normalize the confusion matrix\n",
    "\n",
    "# values for ROC curve\n",
    "# Convert model output to probabilities and plot ROC curve\n",
    "y_probs = bst.predict(X_val, num_iteration=bst.best_iteration)\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# save the values to a file\n",
    "with open('2.9 LightGBM.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'fpr': fpr, 'tpr': tpr, 'roc_auc': roc_auc, 'cm_percentage': cm_percentage, 'report': report\n",
    "    }, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
