{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ponnayo danne kellek aduwa gaman laga inna kol...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ape harak samjeta eka honda adrshyak</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tpita pisuda yako man htuwe atta kiyala aiyo</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kimbak eduwoth ape untath amma thaththawath pe...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lisan nathawa yanna puluwan yako api dannawa o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_hate\n",
       "0  ponnayo danne kellek aduwa gaman laga inna kol...     True\n",
       "1               ape harak samjeta eka honda adrshyak    False\n",
       "2       tpita pisuda yako man htuwe atta kiyala aiyo    False\n",
       "3  kimbak eduwoth ape untath amma thaththawath pe...     True\n",
       "4  lisan nathawa yanna puluwan yako api dannawa o...    False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "column_names = [\"text\", \"is_hate\"]\n",
    "\n",
    "df = pd.read_csv('1.preprocessed_data.csv', on_bad_lines='skip', sep=\",\", encoding='iso-8859-1', header=0, names=column_names)\n",
    "df['is_hate'] = df['is_hate'].astype(bool)\n",
    "df['text'] = df['text'].astype('str')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess your data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load data (sample code, you might already have this df loaded)\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Splitting the data into train and test\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df['text'], df['is_hate'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenizing and padding\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "max_length = max([len(seq) for seq in train_sequences])\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a FastText Model with Gensim\n",
    "import gensim\n",
    "from gensim.models import FastText\n",
    "\n",
    "# Tokenize sentences\n",
    "sentences = df['text'].apply(gensim.utils.simple_preprocess)\n",
    "\n",
    "# Train FastText model\n",
    "ft_model = FastText(sentences, vector_size=100, window=5, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Embedding Matrix\n",
    "import numpy as np\n",
    "\n",
    "embedding_dim = 100  # Matches the vector_size parameter used when training the FastText model\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = ft_model.wv[word]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        print(word)\n",
    "        # word not in FastText model, leaving as zero vector\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 82, 100)           688400    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 78, 128)           64128     \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 128)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 753829 (2.88 MB)\n",
      "Trainable params: 65429 (255.58 KB)\n",
      "Non-trainable params: 688400 (2.63 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "56/56 [==============================] - 1s 6ms/step - loss: 0.6858 - accuracy: 0.5805 - val_loss: 0.6817 - val_accuracy: 0.5896\n",
      "Epoch 2/5\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.6783 - accuracy: 0.5913 - val_loss: 0.6778 - val_accuracy: 0.5896\n",
      "Epoch 3/5\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.6757 - accuracy: 0.5913 - val_loss: 0.6764 - val_accuracy: 0.5896\n",
      "Epoch 4/5\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.5913 - val_loss: 0.6764 - val_accuracy: 0.5896\n",
      "Epoch 5/5\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.6712 - accuracy: 0.5913 - val_loss: 0.6748 - val_accuracy: 0.5896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28f920310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the CNN model\n",
    "model.fit(train_padded, train_labels, epochs=5, validation_data=(test_padded, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 5ms/step\n",
      "[[0.4269493 ]\n",
      " [0.454769  ]\n",
      " [0.4888233 ]\n",
      " [0.3408548 ]\n",
      " [0.29977724]\n",
      " [0.35851875]\n",
      " [0.4888233 ]\n",
      " [0.32511926]\n",
      " [0.4348218 ]\n",
      " [0.43150494]\n",
      " [0.39510137]\n",
      " [0.41197506]\n",
      " [0.41088197]\n",
      " [0.38103807]\n",
      " [0.38491568]\n",
      " [0.46349105]\n",
      " [0.4078083 ]\n",
      " [0.4888233 ]\n",
      " [0.23064591]\n",
      " [0.4569959 ]\n",
      " [0.3239627 ]\n",
      " [0.3801457 ]\n",
      " [0.42797872]\n",
      " [0.34066918]\n",
      " [0.4888233 ]\n",
      " [0.37638223]\n",
      " [0.4609834 ]\n",
      " [0.3252383 ]\n",
      " [0.4888233 ]\n",
      " [0.435411  ]\n",
      " [0.35809487]\n",
      " [0.34275714]\n",
      " [0.45861515]\n",
      " [0.46229878]\n",
      " [0.4888233 ]\n",
      " [0.3448648 ]\n",
      " [0.4888233 ]\n",
      " [0.4888233 ]\n",
      " [0.47834533]\n",
      " [0.4888233 ]\n",
      " [0.30226204]\n",
      " [0.47676623]\n",
      " [0.40603128]\n",
      " [0.376303  ]\n",
      " [0.44517708]\n",
      " [0.4888233 ]\n",
      " [0.30885115]\n",
      " [0.32423347]\n",
      " [0.42652956]\n",
      " [0.4409944 ]\n",
      " [0.41821426]\n",
      " [0.4888233 ]\n",
      " [0.3394037 ]\n",
      " [0.44287235]\n",
      " [0.4888233 ]\n",
      " [0.3955396 ]\n",
      " [0.39323568]\n",
      " [0.44096822]\n",
      " [0.384202  ]\n",
      " [0.46852863]\n",
      " [0.39788705]\n",
      " [0.26962206]\n",
      " [0.33837238]\n",
      " [0.37899104]\n",
      " [0.36099255]\n",
      " [0.27832526]\n",
      " [0.36771366]\n",
      " [0.4123094 ]\n",
      " [0.35872996]\n",
      " [0.32456473]\n",
      " [0.4081808 ]\n",
      " [0.405722  ]\n",
      " [0.36287013]\n",
      " [0.33348778]\n",
      " [0.3681184 ]\n",
      " [0.39842582]\n",
      " [0.33296964]\n",
      " [0.4888233 ]\n",
      " [0.40151358]\n",
      " [0.39960444]\n",
      " [0.44436786]\n",
      " [0.40629038]\n",
      " [0.36967567]\n",
      " [0.47462812]\n",
      " [0.44110304]\n",
      " [0.35414177]\n",
      " [0.39057118]\n",
      " [0.4453552 ]\n",
      " [0.38180906]\n",
      " [0.4405337 ]\n",
      " [0.48289233]\n",
      " [0.4888233 ]\n",
      " [0.43222407]\n",
      " [0.40384397]\n",
      " [0.44774246]\n",
      " [0.3522731 ]\n",
      " [0.40579668]\n",
      " [0.38660258]\n",
      " [0.48130506]\n",
      " [0.40666237]\n",
      " [0.4649905 ]\n",
      " [0.40290806]\n",
      " [0.4888233 ]\n",
      " [0.23021221]\n",
      " [0.47547752]\n",
      " [0.462953  ]\n",
      " [0.40698382]\n",
      " [0.45602092]\n",
      " [0.340004  ]\n",
      " [0.23774797]\n",
      " [0.46775538]\n",
      " [0.29131535]\n",
      " [0.42037213]\n",
      " [0.4805249 ]\n",
      " [0.4669022 ]\n",
      " [0.45184323]\n",
      " [0.47700292]\n",
      " [0.35410005]\n",
      " [0.27616757]\n",
      " [0.44123653]\n",
      " [0.29263952]\n",
      " [0.44074464]\n",
      " [0.328533  ]\n",
      " [0.3260732 ]\n",
      " [0.40446055]\n",
      " [0.29451427]\n",
      " [0.37321478]\n",
      " [0.3952259 ]\n",
      " [0.34678307]\n",
      " [0.38611117]\n",
      " [0.36887237]\n",
      " [0.4888233 ]\n",
      " [0.40522513]\n",
      " [0.3534469 ]\n",
      " [0.4888233 ]\n",
      " [0.46256876]\n",
      " [0.4888233 ]\n",
      " [0.37345132]\n",
      " [0.4546083 ]\n",
      " [0.30752453]\n",
      " [0.45919672]\n",
      " [0.40171367]\n",
      " [0.4296493 ]\n",
      " [0.4888233 ]\n",
      " [0.48375067]\n",
      " [0.3548111 ]\n",
      " [0.4888233 ]\n",
      " [0.4551162 ]\n",
      " [0.3158286 ]\n",
      " [0.36289224]\n",
      " [0.39832655]\n",
      " [0.32786578]\n",
      " [0.40750557]\n",
      " [0.3809575 ]\n",
      " [0.1664529 ]\n",
      " [0.4888233 ]\n",
      " [0.44096822]\n",
      " [0.4189156 ]\n",
      " [0.3629553 ]\n",
      " [0.4622557 ]\n",
      " [0.36327645]\n",
      " [0.42005014]\n",
      " [0.4882537 ]\n",
      " [0.4066785 ]\n",
      " [0.30607006]\n",
      " [0.42871824]\n",
      " [0.4888233 ]\n",
      " [0.43454212]\n",
      " [0.45610172]\n",
      " [0.44599983]\n",
      " [0.3604856 ]\n",
      " [0.38491136]\n",
      " [0.4888233 ]\n",
      " [0.43918788]\n",
      " [0.4888233 ]\n",
      " [0.26964936]\n",
      " [0.4888233 ]\n",
      " [0.4888233 ]\n",
      " [0.4434473 ]\n",
      " [0.43552715]\n",
      " [0.35821706]\n",
      " [0.4888233 ]\n",
      " [0.403913  ]\n",
      " [0.43716133]\n",
      " [0.44959953]\n",
      " [0.4888233 ]\n",
      " [0.4888233 ]\n",
      " [0.46055615]\n",
      " [0.3782677 ]\n",
      " [0.44096822]\n",
      " [0.4888233 ]\n",
      " [0.3257548 ]\n",
      " [0.4633133 ]\n",
      " [0.47831276]\n",
      " [0.33868742]\n",
      " [0.39190128]\n",
      " [0.31157273]\n",
      " [0.44324344]\n",
      " [0.4888233 ]\n",
      " [0.4681548 ]\n",
      " [0.41407326]\n",
      " [0.42648652]\n",
      " [0.39912435]\n",
      " [0.34192848]\n",
      " [0.46888307]\n",
      " [0.41578144]\n",
      " [0.4888233 ]\n",
      " [0.45714903]\n",
      " [0.24212506]\n",
      " [0.38390946]\n",
      " [0.32209015]\n",
      " [0.42900282]\n",
      " [0.39945325]\n",
      " [0.4057017 ]\n",
      " [0.24998486]\n",
      " [0.47912535]\n",
      " [0.4281809 ]\n",
      " [0.42458063]\n",
      " [0.399394  ]\n",
      " [0.39662048]\n",
      " [0.3387456 ]\n",
      " [0.3342503 ]\n",
      " [0.4888233 ]\n",
      " [0.26574826]\n",
      " [0.4888233 ]\n",
      " [0.3881413 ]\n",
      " [0.34382018]\n",
      " [0.4888233 ]\n",
      " [0.4888233 ]\n",
      " [0.37657055]\n",
      " [0.4553351 ]\n",
      " [0.40638652]\n",
      " [0.39112198]\n",
      " [0.4888233 ]\n",
      " [0.4888233 ]\n",
      " [0.42993823]\n",
      " [0.4682888 ]\n",
      " [0.3606561 ]\n",
      " [0.39631614]\n",
      " [0.39758122]\n",
      " [0.48111936]\n",
      " [0.44584838]\n",
      " [0.4888233 ]\n",
      " [0.39365402]\n",
      " [0.46949807]\n",
      " [0.4888233 ]\n",
      " [0.38437095]\n",
      " [0.4016866 ]\n",
      " [0.4888233 ]\n",
      " [0.44008517]\n",
      " [0.4888233 ]\n",
      " [0.3923931 ]\n",
      " [0.4888233 ]\n",
      " [0.4029458 ]\n",
      " [0.4043726 ]\n",
      " [0.42672408]\n",
      " [0.47021845]\n",
      " [0.4664033 ]\n",
      " [0.40022275]\n",
      " [0.4888233 ]\n",
      " [0.40452713]\n",
      " [0.4078033 ]\n",
      " [0.40902317]\n",
      " [0.4888233 ]\n",
      " [0.4008337 ]\n",
      " [0.47441232]\n",
      " [0.47385108]\n",
      " [0.4888233 ]\n",
      " [0.46759802]\n",
      " [0.48400712]\n",
      " [0.3809575 ]\n",
      " [0.4044626 ]\n",
      " [0.48365808]\n",
      " [0.3896986 ]\n",
      " [0.3271509 ]\n",
      " [0.4888233 ]\n",
      " [0.48028436]\n",
      " [0.4649077 ]\n",
      " [0.45059437]\n",
      " [0.364133  ]\n",
      " [0.4888233 ]\n",
      " [0.4563766 ]\n",
      " [0.27002588]\n",
      " [0.25963882]\n",
      " [0.38175285]\n",
      " [0.47245735]\n",
      " [0.4888233 ]\n",
      " [0.29287288]\n",
      " [0.30069658]\n",
      " [0.41073516]\n",
      " [0.41662487]\n",
      " [0.3400731 ]\n",
      " [0.3510353 ]\n",
      " [0.3942012 ]\n",
      " [0.40294576]\n",
      " [0.36824578]\n",
      " [0.3272245 ]\n",
      " [0.33974224]\n",
      " [0.4888233 ]\n",
      " [0.30656904]\n",
      " [0.44096822]\n",
      " [0.4888233 ]\n",
      " [0.47277606]\n",
      " [0.4253438 ]\n",
      " [0.3663262 ]\n",
      " [0.29905874]\n",
      " [0.1976236 ]\n",
      " [0.44793406]\n",
      " [0.47802407]\n",
      " [0.30726668]\n",
      " [0.43740395]\n",
      " [0.39951977]\n",
      " [0.4206687 ]\n",
      " [0.2492361 ]\n",
      " [0.44096822]\n",
      " [0.4888233 ]\n",
      " [0.36742154]\n",
      " [0.4888233 ]\n",
      " [0.43090984]\n",
      " [0.3847483 ]\n",
      " [0.34398067]\n",
      " [0.34925085]\n",
      " [0.4593964 ]\n",
      " [0.4888233 ]\n",
      " [0.48244923]\n",
      " [0.40482292]\n",
      " [0.4410413 ]\n",
      " [0.4116759 ]\n",
      " [0.44096822]\n",
      " [0.481252  ]\n",
      " [0.25751063]\n",
      " [0.3226655 ]\n",
      " [0.482832  ]\n",
      " [0.3538497 ]\n",
      " [0.42929247]\n",
      " [0.30231932]\n",
      " [0.3738147 ]\n",
      " [0.42677644]\n",
      " [0.4888233 ]\n",
      " [0.48869547]\n",
      " [0.43867257]\n",
      " [0.4357542 ]\n",
      " [0.30953997]\n",
      " [0.47772056]\n",
      " [0.40588135]\n",
      " [0.46859136]\n",
      " [0.39194793]\n",
      " [0.48336616]\n",
      " [0.34538853]\n",
      " [0.34510788]\n",
      " [0.3861484 ]\n",
      " [0.30556902]\n",
      " [0.39834473]\n",
      " [0.32471842]\n",
      " [0.4888233 ]\n",
      " [0.32938635]\n",
      " [0.39342308]\n",
      " [0.3581223 ]\n",
      " [0.48359764]\n",
      " [0.46564198]\n",
      " [0.2911943 ]\n",
      " [0.33305335]\n",
      " [0.48086303]\n",
      " [0.48158562]\n",
      " [0.19407652]\n",
      " [0.47362944]\n",
      " [0.37552637]\n",
      " [0.4888233 ]\n",
      " [0.46243775]\n",
      " [0.39500728]\n",
      " [0.36839586]\n",
      " [0.4299709 ]\n",
      " [0.4325851 ]\n",
      " [0.48593953]\n",
      " [0.44096822]\n",
      " [0.3426266 ]\n",
      " [0.47020337]\n",
      " [0.37620527]\n",
      " [0.46425194]\n",
      " [0.43563873]\n",
      " [0.43705383]\n",
      " [0.43281683]\n",
      " [0.4888233 ]\n",
      " [0.40846795]\n",
      " [0.34975564]\n",
      " [0.44096822]\n",
      " [0.35236713]\n",
      " [0.46443558]\n",
      " [0.42847967]\n",
      " [0.40539688]\n",
      " [0.37789857]\n",
      " [0.41297638]\n",
      " [0.4888233 ]\n",
      " [0.47280025]\n",
      " [0.39492238]\n",
      " [0.45078528]\n",
      " [0.3951324 ]\n",
      " [0.48197052]\n",
      " [0.4888233 ]\n",
      " [0.3724453 ]\n",
      " [0.4888233 ]\n",
      " [0.4888233 ]\n",
      " [0.31675935]\n",
      " [0.35722035]\n",
      " [0.4621927 ]\n",
      " [0.47432366]\n",
      " [0.43537998]\n",
      " [0.400675  ]\n",
      " [0.4888233 ]\n",
      " [0.41888845]\n",
      " [0.41136703]\n",
      " [0.47132826]\n",
      " [0.38500658]\n",
      " [0.41407648]\n",
      " [0.34047002]\n",
      " [0.27561852]\n",
      " [0.41044495]\n",
      " [0.4888233 ]\n",
      " [0.4888233 ]\n",
      " [0.38366476]\n",
      " [0.4294891 ]\n",
      " [0.27721035]\n",
      " [0.44096822]\n",
      " [0.4736529 ]\n",
      " [0.44882014]\n",
      " [0.4888233 ]\n",
      " [0.44999793]\n",
      " [0.41893432]\n",
      " [0.3137006 ]\n",
      " [0.3549937 ]\n",
      " [0.4094399 ]\n",
      " [0.40985042]\n",
      " [0.4888233 ]\n",
      " [0.32772404]\n",
      " [0.23892368]\n",
      " [0.48835534]\n",
      " [0.36465028]\n",
      " [0.4888233 ]\n",
      " [0.36324108]\n",
      " [0.36077228]\n",
      " [0.43086398]]\n",
      "14/14 [==============================] - 0s 6ms/step\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "print(model.predict(test_padded))\n",
    "predictions = (model.predict(test_padded) > 0.5).astype('int32').flatten()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      1.00      0.74       260\n",
      "        True       0.00      0.00      0.00       181\n",
      "\n",
      "    accuracy                           0.59       441\n",
      "   macro avg       0.29      0.50      0.37       441\n",
      "weighted avg       0.35      0.59      0.44       441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meuru/Projects/icbt/project/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/meuru/Projects/icbt/project/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/meuru/Projects/icbt/project/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the metrics\n",
    "from sklearn.metrics import classification_report\n",
    "print(predictions)\n",
    "\n",
    "report = classification_report(test_labels, predictions)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]]\n",
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import pickle\n",
    "# values for confusion matrix\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # normalize the confusion matrix\n",
    "print(cm_percentage)\n",
    "\n",
    "# values for ROC curve\n",
    "# Convert model output to probabilities and plot ROC curve\n",
    "y_pred_prob = model.predict(test_padded)\n",
    "fpr, tpr, thresholds = roc_curve(test_labels, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "\n",
    "# save the values to a file\n",
    "with open('2.4 CNN with fasttext model training.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'fpr': fpr, 'tpr': tpr, 'roc_auc': roc_auc, 'cm_percentage': cm_percentage, 'report': report\n",
    "    }, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
