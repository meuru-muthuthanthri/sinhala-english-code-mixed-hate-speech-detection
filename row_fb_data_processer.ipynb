{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data.csv\", on_bad_lines='skip',sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Facebook:/<page-id>/posts', 'Facebook:/<post-id>/comments'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(df[[\"query_type\"]])\n",
    "# df.columns\n",
    "df.query_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = df.loc[df['query_type'] == \"Facebook:/<post-id>/comments\"]\n",
    "# comments_df.columns\n",
    "# print(comments_df[['message']])\n",
    "text_df = comments_df[['message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                message\n",
      "22                      Cari gothayaa ubawa kalath madi\n",
      "23                                                  üíûüíûüíû\n",
      "24                                                 G TV\n",
      "25                               ‡∂ú‡∑Ñ‡∂± ‡∂Ö‡∂±‡∑ä‡∂≠‡∑í‡∂∏ ‡∂ú‡∑ê‡∑Ñ‡∑í‡∂Ω‡∑è ‡∂≠‡∂∏‡∑èü§£\n",
      "26        Mekata hrad dapu kattiya gana harima pilikul.\n",
      "...                                                 ...\n",
      "4381                                          ‡∂±‡∑í‡∑Ä‡∂±‡∑ä ‡∑É‡∑î‡∑Ä\n",
      "4382  ‡∂≠‡∑ú‡∂ú‡∑ö ‡∂∏‡∂∫‡∑í‡∂±‡∑è ‡∂Ö‡∂¥‡∑ä‡∂¥‡∂†‡∑ä‡∂†‡∑ì ‡∂Ö‡∂¥‡∑í‡∑Ä ‡∂ª‡∑Ä‡∂ß‡∑ä‡∂ß‡∂Ω‡∑è ‡∂Ö‡∂¥‡∑ö ‡∂†‡∂±‡∑ä‡∂Ø‡∑ö ‡∂ú‡∂≠‡∑ä...\n",
      "4383                 Viraj Vimukthi Lakshitha ‡∂ú‡∑ú‡∂∏‡∑ä‡∂∂‡∂∫‡∑í‡∂∫‡∑è\n",
      "4384                                         Budusarani\n",
      "4385                                                NaN\n",
      "\n",
      "[4210 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(text_df)\n",
    "text_df.to_csv('messages.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8l/0dr6g72x2rq8wcm2j5c630j00000gn/T/ipykernel_76671/3476353599.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_df['message'] = text_df['message'].apply(remove_emojis)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_emojis(text):\n",
    "    if isinstance(text, str):    \n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                               \"\\U0001F600-\\U0001F64F\"  # Emojis\n",
    "                               \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
    "                               \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
    "                               \"\\U0001F700-\\U0001F77F\"  # Alchemical Symbols\n",
    "                               \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                               \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                               \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                               \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                               \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                               \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                               \"\\U0001F1E6-\\U0001F1FF\"  # Flags (part 1)\n",
    "                               \"\\U0001F3F4-\\U0001F3F4\"  # üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø Flag for England\n",
    "                               \"\\U0001F3F3-\\U0001F3F3\"  # üè≥Ô∏è White Flag\n",
    "                               \"\\U0001F3F3-\\U0001F3F3\"  # üè≥Ô∏è Black Flag\n",
    "                               \"\\U0001F3F3-\\U0001F3F3\"  # üè≥Ô∏è Rainbow Flag\n",
    "                               \"\\U0001F3F3-\\U0001F3F3\"  # üè≥Ô∏è Pirate Flag\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "        return emoji_pattern.sub(r'', text)\n",
    "    else:\n",
    "        print(text)\n",
    "        return \"\"\n",
    "\n",
    "text_df['message'] = text_df['message'].apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22                   Cari gothayaa ubawa kalath madi\n",
      "24                                              G TV\n",
      "26      Mekata hrad dapu kattiya gana harima pilikul\n",
      "27                            Nawagilunoth bandchoon\n",
      "28            There r things ppl can do and can t do\n",
      "                            ...                     \n",
      "4354                                 Congratulations\n",
      "4356                                           Great\n",
      "4358                              Katto mitto whutto\n",
      "4383                        Viraj Vimukthi Lakshitha\n",
      "4384                                      Budusarani\n",
      "Name: message, Length: 1176, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8l/0dr6g72x2rq8wcm2j5c630j00000gn/T/ipykernel_76671/3822762588.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_df['message'] = text_df['message'].apply(clean_text)\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Replace non-alphabetic characters with spaces\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "    \n",
    "    return cleaned_text.strip()\n",
    "text_df['message'] = text_df['message'].apply(clean_text)\n",
    "text_df = text_df[text_df['message'] != '']\n",
    "print(text_df['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.to_csv('processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22                        Cari gothayaa ubawa kalath madi\n",
      "24                                                   G TV\n",
      "25                                  ‡∂ú‡∑Ñ‡∂± ‡∂Ö‡∂±‡∑ä‡∂≠‡∑í‡∂∏ ‡∂ú‡∑ê‡∑Ñ‡∑í‡∂Ω‡∑è ‡∂≠‡∂∏‡∑è\n",
      "26          Mekata hrad dapu kattiya gana harima pilikul.\n",
      "27                                 Nawagilunoth bandchoon\n",
      "                              ...                        \n",
      "4380                                            ‡∂±‡∑í‡∑Ä‡∂±‡∑ä ‡∑É‡∑î‡∑Ä\n",
      "4381                                            ‡∂±‡∑í‡∑Ä‡∂±‡∑ä ‡∑É‡∑î‡∑Ä\n",
      "4382    ‡∂≠‡∑ú‡∂ú‡∑ö ‡∂∏‡∂∫‡∑í‡∂±‡∑è ‡∂Ö‡∂¥‡∑ä‡∂¥‡∂†‡∑ä‡∂†‡∑ì ‡∂Ö‡∂¥‡∑í‡∑Ä ‡∂ª‡∑Ä‡∂ß‡∑ä‡∂ß‡∂Ω‡∑è ‡∂Ö‡∂¥‡∑ö ‡∂†‡∂±‡∑ä‡∂Ø‡∑ö ‡∂ú‡∂≠‡∑ä...\n",
      "4383                   Viraj Vimukthi Lakshitha ‡∂ú‡∑ú‡∂∏‡∑ä‡∂∂‡∂∫‡∑í‡∂∫‡∑è\n",
      "4384                                           Budusarani\n",
      "Name: message, Length: 3238, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text_df = text_df[text_df['message'] != '']\n",
    "print(text_df['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22                    Cari gothayaa ubawa kalath madi\n",
      "24                                               G TV\n",
      "25                                                   \n",
      "26      Mekata hrad dapu kattiya gana harima pilikul.\n",
      "27                             Nawagilunoth bandchoon\n",
      "                            ...                      \n",
      "4380                                                 \n",
      "4381                                                 \n",
      "4382                                                 \n",
      "4383                        Viraj Vimukthi Lakshitha \n",
      "4384                                       Budusarani\n",
      "Name: message, Length: 3238, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def remove_sinhala_and_tamil(text):\n",
    "    sinhala_pattern = re.compile(\"[\\u0D80-\\u0DFF]+\")  # Sinhala Unicode range\n",
    "    tamil_pattern = re.compile(\"[\\u0B80-\\u0BFF]+\")    # Tamil Unicode range\n",
    "\n",
    "    # Replace both Sinhala and Tamil characters\n",
    "    text_without_sinhala = sinhala_pattern.sub(r'', text)\n",
    "    text_without_tamil = tamil_pattern.sub(r'', text_without_sinhala)\n",
    "    \n",
    "    return text_without_tamil\n",
    "text_df['message'] = text_df['message'].apply(remove_sinhala_and_tamil)\n",
    "print(text_df['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22                    Cari gothayaa ubawa kalath madi\n",
      "24                                               G TV\n",
      "25                                                   \n",
      "26      Mekata hrad dapu kattiya gana harima pilikul.\n",
      "27                             Nawagilunoth bandchoon\n",
      "                            ...                      \n",
      "4380                                                 \n",
      "4381                                                 \n",
      "4382                                                 \n",
      "4383                        Viraj Vimukthi Lakshitha \n",
      "4384                                       Budusarani\n",
      "Name: message, Length: 3238, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text_df = text_df.dropna(subset=['message',])\n",
    "print(text_df['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.to_csv('processed_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
