{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data.csv\", on_bad_lines='skip',sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Facebook:/<page-id>/posts', 'Facebook:/<post-id>/comments'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(df[[\"query_type\"]])\n",
    "# df.columns\n",
    "df.query_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = df.loc[df['query_type'] == \"Facebook:/<post-id>/comments\"]\n",
    "# comments_df.columns\n",
    "# print(comments_df[['message']])\n",
    "text_df = comments_df[['message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                message\n",
      "22                      Cari gothayaa ubawa kalath madi\n",
      "23                                                  💞💞💞\n",
      "24                                                 G TV\n",
      "25                               ගහන අන්තිම ගැහිලා තමා🤣\n",
      "26        Mekata hrad dapu kattiya gana harima pilikul.\n",
      "...                                                 ...\n",
      "4381                                          නිවන් සුව\n",
      "4382  තොගේ මයිනා අප්පච්චී අපිව රවට්ටලා අපේ චන්දේ ගත්...\n",
      "4383                 Viraj Vimukthi Lakshitha ගොම්බයියා\n",
      "4384                                         Budusarani\n",
      "4385                                                NaN\n",
      "\n",
      "[4210 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(text_df)\n",
    "text_df.to_csv('messages.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8l/0dr6g72x2rq8wcm2j5c630j00000gn/T/ipykernel_76671/3476353599.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_df['message'] = text_df['message'].apply(remove_emojis)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_emojis(text):\n",
    "    if isinstance(text, str):    \n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                               \"\\U0001F600-\\U0001F64F\"  # Emojis\n",
    "                               \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
    "                               \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
    "                               \"\\U0001F700-\\U0001F77F\"  # Alchemical Symbols\n",
    "                               \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                               \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                               \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                               \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                               \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                               \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                               \"\\U0001F1E6-\\U0001F1FF\"  # Flags (part 1)\n",
    "                               \"\\U0001F3F4-\\U0001F3F4\"  # 🏴󠁧󠁢󠁥󠁮󠁧󠁿 Flag for England\n",
    "                               \"\\U0001F3F3-\\U0001F3F3\"  # 🏳️ White Flag\n",
    "                               \"\\U0001F3F3-\\U0001F3F3\"  # 🏳️ Black Flag\n",
    "                               \"\\U0001F3F3-\\U0001F3F3\"  # 🏳️ Rainbow Flag\n",
    "                               \"\\U0001F3F3-\\U0001F3F3\"  # 🏳️ Pirate Flag\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "        return emoji_pattern.sub(r'', text)\n",
    "    else:\n",
    "        print(text)\n",
    "        return \"\"\n",
    "\n",
    "text_df['message'] = text_df['message'].apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22                   Cari gothayaa ubawa kalath madi\n",
      "24                                              G TV\n",
      "26      Mekata hrad dapu kattiya gana harima pilikul\n",
      "27                            Nawagilunoth bandchoon\n",
      "28            There r things ppl can do and can t do\n",
      "                            ...                     \n",
      "4354                                 Congratulations\n",
      "4356                                           Great\n",
      "4358                              Katto mitto whutto\n",
      "4383                        Viraj Vimukthi Lakshitha\n",
      "4384                                      Budusarani\n",
      "Name: message, Length: 1176, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8l/0dr6g72x2rq8wcm2j5c630j00000gn/T/ipykernel_76671/3822762588.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_df['message'] = text_df['message'].apply(clean_text)\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Replace non-alphabetic characters with spaces\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "    \n",
    "    return cleaned_text.strip()\n",
    "text_df['message'] = text_df['message'].apply(clean_text)\n",
    "text_df = text_df[text_df['message'] != '']\n",
    "print(text_df['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.to_csv('processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22                        Cari gothayaa ubawa kalath madi\n",
      "24                                                   G TV\n",
      "25                                  ගහන අන්තිම ගැහිලා තමා\n",
      "26          Mekata hrad dapu kattiya gana harima pilikul.\n",
      "27                                 Nawagilunoth bandchoon\n",
      "                              ...                        \n",
      "4380                                            නිවන් සුව\n",
      "4381                                            නිවන් සුව\n",
      "4382    තොගේ මයිනා අප්පච්චී අපිව රවට්ටලා අපේ චන්දේ ගත්...\n",
      "4383                   Viraj Vimukthi Lakshitha ගොම්බයියා\n",
      "4384                                           Budusarani\n",
      "Name: message, Length: 3238, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text_df = text_df[text_df['message'] != '']\n",
    "print(text_df['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22                    Cari gothayaa ubawa kalath madi\n",
      "24                                               G TV\n",
      "25                                                   \n",
      "26      Mekata hrad dapu kattiya gana harima pilikul.\n",
      "27                             Nawagilunoth bandchoon\n",
      "                            ...                      \n",
      "4380                                                 \n",
      "4381                                                 \n",
      "4382                                                 \n",
      "4383                        Viraj Vimukthi Lakshitha \n",
      "4384                                       Budusarani\n",
      "Name: message, Length: 3238, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def remove_sinhala_and_tamil(text):\n",
    "    sinhala_pattern = re.compile(\"[\\u0D80-\\u0DFF]+\")  # Sinhala Unicode range\n",
    "    tamil_pattern = re.compile(\"[\\u0B80-\\u0BFF]+\")    # Tamil Unicode range\n",
    "\n",
    "    # Replace both Sinhala and Tamil characters\n",
    "    text_without_sinhala = sinhala_pattern.sub(r'', text)\n",
    "    text_without_tamil = tamil_pattern.sub(r'', text_without_sinhala)\n",
    "    \n",
    "    return text_without_tamil\n",
    "text_df['message'] = text_df['message'].apply(remove_sinhala_and_tamil)\n",
    "print(text_df['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22                    Cari gothayaa ubawa kalath madi\n",
      "24                                               G TV\n",
      "25                                                   \n",
      "26      Mekata hrad dapu kattiya gana harima pilikul.\n",
      "27                             Nawagilunoth bandchoon\n",
      "                            ...                      \n",
      "4380                                                 \n",
      "4381                                                 \n",
      "4382                                                 \n",
      "4383                        Viraj Vimukthi Lakshitha \n",
      "4384                                       Budusarani\n",
      "Name: message, Length: 3238, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text_df = text_df.dropna(subset=['message',])\n",
    "print(text_df['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.to_csv('processed_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
