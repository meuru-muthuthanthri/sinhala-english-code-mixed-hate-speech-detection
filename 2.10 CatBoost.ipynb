{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ponnayo danne kellek aduwa gaman laga inna kol...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ape harak samjeta eka honda adrshyak</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tpita pisuda yako man htuwe atta kiyala aiyo</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kimbak eduwoth ape untath amma thaththawath pe...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lisan nathawa yanna puluwan yako api dannawa o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_hate\n",
       "0  ponnayo danne kellek aduwa gaman laga inna kol...     True\n",
       "1               ape harak samjeta eka honda adrshyak    False\n",
       "2       tpita pisuda yako man htuwe atta kiyala aiyo    False\n",
       "3  kimbak eduwoth ape untath amma thaththawath pe...     True\n",
       "4  lisan nathawa yanna puluwan yako api dannawa o...    False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "column_names = [\"text\", \"is_hate\"]\n",
    "\n",
    "df = pd.read_csv('1.preprocessed_data.csv', on_bad_lines='skip', sep=\",\", encoding='iso-8859-1', header=0, names=column_names)\n",
    "df['is_hate'] = df['is_hate'].astype(bool)\n",
    "df['text'] = df['text'].astype('str')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7841160\tbest: 0.7841160 (0)\ttotal: 82.9ms\tremaining: 1m 22s\n",
      "100:\ttest: 0.8664365\tbest: 0.8683702 (25)\ttotal: 3.03s\tremaining: 27s\n",
      "200:\ttest: 0.8673608\tbest: 0.8683702 (25)\ttotal: 5.83s\tremaining: 23.2s\n",
      "300:\ttest: 0.8674139\tbest: 0.8683702 (25)\ttotal: 8.75s\tremaining: 20.3s\n",
      "400:\ttest: 0.8657034\tbest: 0.8683702 (25)\ttotal: 11.8s\tremaining: 17.6s\n",
      "500:\ttest: 0.8604335\tbest: 0.8683702 (25)\ttotal: 14.6s\tremaining: 14.6s\n",
      "600:\ttest: 0.8589885\tbest: 0.8683702 (25)\ttotal: 17.4s\tremaining: 11.6s\n",
      "700:\ttest: 0.8566617\tbest: 0.8683702 (25)\ttotal: 20.2s\tremaining: 8.6s\n",
      "800:\ttest: 0.8549618\tbest: 0.8683702 (25)\ttotal: 23.3s\tremaining: 5.78s\n",
      "900:\ttest: 0.8535805\tbest: 0.8683702 (25)\ttotal: 26.1s\tremaining: 2.87s\n",
      "999:\ttest: 0.8518168\tbest: 0.8683702 (25)\ttotal: 28.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8683701657\n",
      "bestIteration = 25\n",
      "\n",
      "Shrink model to first 26 iterations.\n",
      "Accuracy: 0.8117913832199547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86       260\n",
      "           1       0.90      0.61      0.73       181\n",
      "\n",
      "    accuracy                           0.81       441\n",
      "   macro avg       0.84      0.78      0.79       441\n",
      "weighted avg       0.83      0.81      0.80       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# df = pd.read_csv('your_dataset.csv')  # Uncomment this if reading from a CSV\n",
    "\n",
    "# 1. Data preprocessing\n",
    "# Convert boolean to integer for the 'is_hate' column\n",
    "df['is_hate'] = df['is_hate'].astype(int)\n",
    "\n",
    "# 2. Splitting the dataset into training and testing sets\n",
    "X = df[['text']]  # Note the double brackets which will give us a DataFrame\n",
    "y = df['is_hate']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Pool(data=X_train, label=y_train, text_features=['text'])\n",
    "test_dataset = Pool(data=X_test, label=y_test, text_features=['text'])\n",
    "\n",
    "# 3. Building and training a CatBoost classifier\n",
    "model = CatBoostClassifier(iterations=1000, # or more iterations based on your dataset size and complexity\n",
    "                           learning_rate=0.05,\n",
    "                           depth=7,\n",
    "                           loss_function='Logloss',\n",
    "                           eval_metric='AUC',\n",
    "                           verbose=100,\n",
    "                           text_features=[0]) # Use GPU for faster training, remove if you don't have GPU\n",
    "\n",
    "model.fit(train_dataset, eval_set=test_dataset, plot=False)\n",
    "\n",
    "# 4. Evaluating the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# To predict for a new text string\n",
    "# new_text = [\"Your new text here\"]\n",
    "# prediction = model.predict(new_text)\n",
    "# print(\"Hate speech\" if prediction[0] == 1 else \"Not hate speech\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hate speech\n",
      "Text 1 is Hate speech\n",
      "Text 2 is Not hate speech\n",
      "Text 3 is Hate speech\n"
     ]
    }
   ],
   "source": [
    "# Let's assume your model is trained and is named `model`.\n",
    "\n",
    "# For predicting a single text string:\n",
    "new_text = pd.DataFrame({\"text\": [\"kalakanni deshapaluwo\"]})\n",
    "prediction = model.predict(new_text)\n",
    "\n",
    "print(\"Hate speech\" if prediction[0] == 1 else \"Not hate speech\")\n",
    "\n",
    "# For predicting multiple text strings:\n",
    "new_texts = pd.DataFrame({\"text\": [\"kalakanni deshapaluwo\", \"pissu kelinna epa\", \"okun marila yanna ona\"]})\n",
    "predictions = model.predict(new_texts)\n",
    "\n",
    "for idx, pred in enumerate(predictions):\n",
    "    print(f\"Text {idx + 1} is {'Hate speech' if pred == 1 else 'Not hate speech'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.78      0.95      0.86       260\n",
      "       False       0.90      0.61      0.73       181\n",
      "\n",
      "    accuracy                           0.81       441\n",
      "   macro avg       0.84      0.78      0.79       441\n",
      "weighted avg       0.83      0.81      0.80       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=['True', 'False'])\n",
    "print(report)\n",
    "# values for confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # normalize the confusion matrix\n",
    "\n",
    "# values for ROC curve\n",
    "# Convert model output to probabilities and plot ROC curve\n",
    "y_prob = model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# save the values to a file\n",
    "with open('2.10 CatBoost.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'fpr': fpr, 'tpr': tpr, 'roc_auc': roc_auc, 'cm_percentage': cm_percentage, 'report': report\n",
    "    }, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
