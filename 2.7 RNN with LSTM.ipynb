{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ponnayo danne kellek aduwa gaman laga inna kol...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ape harak samjeta eka honda adrshyak</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tpita pisuda yako man htuwe atta kiyala aiyo</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kimbak eduwoth ape untath amma thaththawath pe...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lisan nathawa yanna puluwan yako api dannawa o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_hate\n",
       "0  ponnayo danne kellek aduwa gaman laga inna kol...     True\n",
       "1               ape harak samjeta eka honda adrshyak    False\n",
       "2       tpita pisuda yako man htuwe atta kiyala aiyo    False\n",
       "3  kimbak eduwoth ape untath amma thaththawath pe...     True\n",
       "4  lisan nathawa yanna puluwan yako api dannawa o...    False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "column_names = [\"text\", \"is_hate\"]\n",
    "\n",
    "df = pd.read_csv('1.preprocessed_data.csv', on_bad_lines='skip', sep=\",\", encoding='iso-8859-1', header=0, names=column_names)\n",
    "df['is_hate'] = df['is_hate'].astype(bool)\n",
    "df['text'] = df['text'].astype('str')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "# Tokenize the text data\n",
    "max_words = 1000  # You can change this based on your dataset\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "\n",
    "# Pad sequences for consistent input size\n",
    "max_length = 30  # You can adjust this value based on your dataset\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Splitting data into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['is_hate'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building the LSTM Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 30, 64)            64000     \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 30, 64)            33024     \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 24)                792       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110257 (430.69 KB)\n",
      "Trainable params: 110257 (430.69 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "embedding_dim = 64  # You can adjust this value\n",
    "model = Sequential([\n",
    "    Embedding(max_words, embedding_dim, input_length=max_length),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "56/56 [==============================] - 3s 24ms/step - loss: 0.6798 - accuracy: 0.5884 - val_loss: 0.6785 - val_accuracy: 0.5760\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 0.6282 - accuracy: 0.6525 - val_loss: 0.5622 - val_accuracy: 0.7664\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 0.4369 - accuracy: 0.8260 - val_loss: 0.4724 - val_accuracy: 0.8005\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 0.3321 - accuracy: 0.8719 - val_loss: 0.4958 - val_accuracy: 0.7732\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 0.2878 - accuracy: 0.8974 - val_loss: 0.5193 - val_accuracy: 0.7823\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 0.2686 - accuracy: 0.9059 - val_loss: 0.5005 - val_accuracy: 0.7914\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 0.2337 - accuracy: 0.9257 - val_loss: 0.5897 - val_accuracy: 0.7732\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 0.2033 - accuracy: 0.9399 - val_loss: 0.7247 - val_accuracy: 0.7574\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 0.2099 - accuracy: 0.9337 - val_loss: 0.7097 - val_accuracy: 0.7800\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 0.1905 - accuracy: 0.9427 - val_loss: 0.7334 - val_accuracy: 0.7642\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10  # You can adjust this value\n",
    "history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test), verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/14 [=>............................] - ETA: 0s - loss: 0.5276 - accuracy: 0.8125"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step - loss: 0.7334 - accuracy: 0.7642\n",
      "Test accuracy: 76.42%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.85      0.81       254\n",
      "        True       0.76      0.64      0.70       187\n",
      "\n",
      "    accuracy                           0.76       441\n",
      "   macro avg       0.76      0.75      0.75       441\n",
      "weighted avg       0.76      0.76      0.76       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Making Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "Hate\n"
     ]
    }
   ],
   "source": [
    "def predict_hate(text):\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    return \"Hate\" if prediction[0][0] > 0.5 else \"Not Hate\"\n",
    "\n",
    "text_input = \"kalakanni deshapaluwo\"\n",
    "print(predict_hate(text_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import pickle\n",
    "import numpy as np\n",
    "# values for confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # normalize the confusion matrix\n",
    "\n",
    "# values for ROC curve\n",
    "# Convert model output to probabilities and plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict(X_test))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# save the values to a file\n",
    "with open('2.7 RNN with LSTM.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'fpr': fpr, 'tpr': tpr, 'roc_auc': roc_auc, 'cm_percentage': cm_percentage, 'report': report\n",
    "    }, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
