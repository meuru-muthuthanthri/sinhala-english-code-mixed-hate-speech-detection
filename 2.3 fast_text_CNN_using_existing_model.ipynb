{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ponnayo danne kellek aduwa gaman laga inna kol...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ape harak samjeta eka honda adrshyak</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tpita pisuda yako man htuwe atta kiyala aiyo</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kimbak eduwoth ape untath amma thaththawath pe...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lisan nathawa yanna puluwan yako api dannawa o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_hate\n",
       "0  ponnayo danne kellek aduwa gaman laga inna kol...     True\n",
       "1               ape harak samjeta eka honda adrshyak    False\n",
       "2       tpita pisuda yako man htuwe atta kiyala aiyo    False\n",
       "3  kimbak eduwoth ape untath amma thaththawath pe...     True\n",
       "4  lisan nathawa yanna puluwan yako api dannawa o...    False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "column_names = [\"text\", \"is_hate\"]\n",
    "\n",
    "df = pd.read_csv('1.preprocessed_data.csv', on_bad_lines='skip', sep=\",\", encoding='iso-8859-1', header=0, names=column_names)\n",
    "df['is_hate'] = df['is_hate'].astype(bool)\n",
    "df['text'] = df['text'].astype('str')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess your data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load data (sample code, you might already have this df loaded)\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Splitting the data into train and test\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df['text'], df['is_hate'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenizing and padding\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "max_length = max([len(seq) for seq in train_sequences])\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing word count: 5509\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'Tokenizer' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/meuru/Projects/icbt/project/2.3 fast_text_CNN_using_existing_model.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meuru/Projects/icbt/project/2.3%20fast_text_CNN_using_existing_model.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meuru/Projects/icbt/project/2.3%20fast_text_CNN_using_existing_model.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMissing word count:\u001b[39m\u001b[39m'\u001b[39m,\u001b[39mlen\u001b[39m(words_not_found))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/meuru/Projects/icbt/project/2.3%20fast_text_CNN_using_existing_model.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mTotal: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39;49m(tokenizer))\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'Tokenizer' has no len()"
     ]
    }
   ],
   "source": [
    "# Download and create FastText embedding matrix\n",
    "import gensim.downloader\n",
    "import numpy as np\n",
    "\n",
    "# Download FastText model\n",
    "fasttext_model = gensim.downloader.load('fasttext-wiki-news-subwords-300')\n",
    "\n",
    "# Create embedding matrix\n",
    "embedding_dim = 300  # as we are using FastText with 300 dimensions\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "words_not_found = []\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = fasttext_model[word]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            words_not_found.append(word)\n",
    "    except KeyError:\n",
    "        # word not in FastText model, leaving as zero vector\n",
    "        words_not_found.append(word)\n",
    "        pass\n",
    "\n",
    "print('Missing word count:',len(words_not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 82, 300)           2065200   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 78, 128)           192128    \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 128)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2258629 (8.62 MB)\n",
      "Trainable params: 193429 (755.58 KB)\n",
      "Non-trainable params: 2065200 (7.88 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the CNN model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.6805 - accuracy: 0.5833 - val_loss: 0.6740 - val_accuracy: 0.5896\n",
      "Epoch 2/5\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.6498 - accuracy: 0.6032 - val_loss: 0.6526 - val_accuracy: 0.5941\n",
      "Epoch 3/5\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.5991 - accuracy: 0.6927 - val_loss: 0.6166 - val_accuracy: 0.6667\n",
      "Epoch 4/5\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.5265 - accuracy: 0.7500 - val_loss: 0.6182 - val_accuracy: 0.6689\n",
      "Epoch 5/5\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 0.4386 - accuracy: 0.8146 - val_loss: 0.6198 - val_accuracy: 0.6712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29c381790>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the CNN model\n",
    "model.fit(train_padded, train_labels, epochs=5, validation_data=(test_padded, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step\n",
      "[0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1\n",
      " 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1\n",
      " 1 0 0 0 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1\n",
      " 1 1 1 0 0 0 0 1 1 1 1 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = (model.predict(test_padded) > 0.5).astype('int32').flatten()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.68      0.82      0.75       260\n",
      "        True       0.64      0.46      0.53       181\n",
      "\n",
      "    accuracy                           0.67       441\n",
      "   macro avg       0.66      0.64      0.64       441\n",
      "weighted avg       0.67      0.67      0.66       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(test_labels, predictions)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step\n",
      "[[0.34647718]\n",
      " [0.52539986]\n",
      " [0.39229622]\n",
      " [0.10973633]\n",
      " [0.19986606]\n",
      " [0.3698384 ]\n",
      " [0.5548922 ]\n",
      " [0.41199905]\n",
      " [0.847774  ]\n",
      " [0.23248836]\n",
      " [0.6201677 ]\n",
      " [0.9179381 ]\n",
      " [0.08489243]\n",
      " [0.3483674 ]\n",
      " [0.92974085]\n",
      " [0.96216625]\n",
      " [0.3716352 ]\n",
      " [0.26907384]\n",
      " [0.34647718]\n",
      " [0.3241305 ]\n",
      " [0.14807296]\n",
      " [0.06422706]\n",
      " [0.3605152 ]\n",
      " [0.28082797]\n",
      " [0.621121  ]\n",
      " [0.34647718]\n",
      " [0.3961661 ]\n",
      " [0.34647718]\n",
      " [0.2208572 ]\n",
      " [0.76908267]\n",
      " [0.34647718]\n",
      " [0.7306307 ]\n",
      " [0.26260352]\n",
      " [0.3583401 ]\n",
      " [0.94860786]\n",
      " [0.34647718]\n",
      " [0.8750165 ]\n",
      " [0.37917215]\n",
      " [0.34647718]\n",
      " [0.67104685]\n",
      " [0.23639774]\n",
      " [0.6850735 ]\n",
      " [0.38228804]\n",
      " [0.07126072]\n",
      " [0.5083216 ]\n",
      " [0.75651824]\n",
      " [0.705012  ]\n",
      " [0.06680728]\n",
      " [0.25946864]\n",
      " [0.38202903]\n",
      " [0.3200393 ]\n",
      " [0.8097526 ]\n",
      " [0.85879093]\n",
      " [0.7204374 ]\n",
      " [0.85863876]\n",
      " [0.29777345]\n",
      " [0.3143661 ]\n",
      " [0.34647718]\n",
      " [0.07665051]\n",
      " [0.26036027]\n",
      " [0.2440533 ]\n",
      " [0.08683968]\n",
      " [0.2222391 ]\n",
      " [0.10737071]\n",
      " [0.32681686]\n",
      " [0.02765866]\n",
      " [0.20241868]\n",
      " [0.48780254]\n",
      " [0.26751933]\n",
      " [0.07477791]\n",
      " [0.917093  ]\n",
      " [0.03695974]\n",
      " [0.37452158]\n",
      " [0.3228785 ]\n",
      " [0.34647718]\n",
      " [0.34647718]\n",
      " [0.7584731 ]\n",
      " [0.35688573]\n",
      " [0.3011362 ]\n",
      " [0.8717398 ]\n",
      " [0.17540719]\n",
      " [0.17302212]\n",
      " [0.34669185]\n",
      " [0.29990757]\n",
      " [0.3837046 ]\n",
      " [0.7326344 ]\n",
      " [0.33094496]\n",
      " [0.0439715 ]\n",
      " [0.26000223]\n",
      " [0.6801638 ]\n",
      " [0.44576502]\n",
      " [0.5838737 ]\n",
      " [0.05832627]\n",
      " [0.34647718]\n",
      " [0.25893945]\n",
      " [0.2400057 ]\n",
      " [0.28831407]\n",
      " [0.12258586]\n",
      " [0.4155421 ]\n",
      " [0.44714993]\n",
      " [0.24182163]\n",
      " [0.01720427]\n",
      " [0.10281383]\n",
      " [0.34647718]\n",
      " [0.7043067 ]\n",
      " [0.9723595 ]\n",
      " [0.38719165]\n",
      " [0.68511295]\n",
      " [0.17121519]\n",
      " [0.10633493]\n",
      " [0.6288747 ]\n",
      " [0.34647718]\n",
      " [0.3459762 ]\n",
      " [0.9677429 ]\n",
      " [0.01350667]\n",
      " [0.35589632]\n",
      " [0.10200995]\n",
      " [0.4078864 ]\n",
      " [0.42253783]\n",
      " [0.13796672]\n",
      " [0.29594097]\n",
      " [0.76084006]\n",
      " [0.39121002]\n",
      " [0.1596824 ]\n",
      " [0.5741573 ]\n",
      " [0.2604628 ]\n",
      " [0.4413953 ]\n",
      " [0.12600288]\n",
      " [0.07634395]\n",
      " [0.6419493 ]\n",
      " [0.212286  ]\n",
      " [0.6091689 ]\n",
      " [0.37358525]\n",
      " [0.37762934]\n",
      " [0.85987264]\n",
      " [0.538291  ]\n",
      " [0.34406972]\n",
      " [0.26905218]\n",
      " [0.8288892 ]\n",
      " [0.8569178 ]\n",
      " [0.7125132 ]\n",
      " [0.34647718]\n",
      " [0.2228302 ]\n",
      " [0.82440746]\n",
      " [0.5719793 ]\n",
      " [0.34647718]\n",
      " [0.2316188 ]\n",
      " [0.7991617 ]\n",
      " [0.33242604]\n",
      " [0.08579046]\n",
      " [0.13362743]\n",
      " [0.34647718]\n",
      " [0.3869891 ]\n",
      " [0.34647718]\n",
      " [0.11636677]\n",
      " [0.930526  ]\n",
      " [0.34647718]\n",
      " [0.34647718]\n",
      " [0.29203105]\n",
      " [0.8530661 ]\n",
      " [0.34647718]\n",
      " [0.2585456 ]\n",
      " [0.58232844]\n",
      " [0.26787415]\n",
      " [0.3819041 ]\n",
      " [0.46372062]\n",
      " [0.49517626]\n",
      " [0.863393  ]\n",
      " [0.2312519 ]\n",
      " [0.61872935]\n",
      " [0.03695974]\n",
      " [0.1535914 ]\n",
      " [0.6465929 ]\n",
      " [0.5764039 ]\n",
      " [0.08690502]\n",
      " [0.7005056 ]\n",
      " [0.25339073]\n",
      " [0.0749583 ]\n",
      " [0.3478212 ]\n",
      " [0.72001594]\n",
      " [0.11466228]\n",
      " [0.92607456]\n",
      " [0.9568843 ]\n",
      " [0.061279  ]\n",
      " [0.04457333]\n",
      " [0.5675302 ]\n",
      " [0.46460438]\n",
      " [0.4030145 ]\n",
      " [0.3698384 ]\n",
      " [0.34647718]\n",
      " [0.13410655]\n",
      " [0.6868598 ]\n",
      " [0.12039281]\n",
      " [0.05862741]\n",
      " [0.17858258]\n",
      " [0.6920506 ]\n",
      " [0.95809114]\n",
      " [0.6600903 ]\n",
      " [0.6139027 ]\n",
      " [0.3370477 ]\n",
      " [0.17329912]\n",
      " [0.34647718]\n",
      " [0.02291693]\n",
      " [0.8240181 ]\n",
      " [0.03016912]\n",
      " [0.26110116]\n",
      " [0.21395272]\n",
      " [0.34647718]\n",
      " [0.32681686]\n",
      " [0.34669185]\n",
      " [0.08564744]\n",
      " [0.7528101 ]\n",
      " [0.45703873]\n",
      " [0.6812831 ]\n",
      " [0.17754348]\n",
      " [0.31839386]\n",
      " [0.32650548]\n",
      " [0.1396832 ]\n",
      " [0.26327887]\n",
      " [0.34647718]\n",
      " [0.34647718]\n",
      " [0.04633279]\n",
      " [0.4395219 ]\n",
      " [0.1535914 ]\n",
      " [0.83681893]\n",
      " [0.07275755]\n",
      " [0.1471785 ]\n",
      " [0.9448048 ]\n",
      " [0.32081553]\n",
      " [0.19463313]\n",
      " [0.07205833]\n",
      " [0.32937658]\n",
      " [0.34647718]\n",
      " [0.26158774]\n",
      " [0.3242274 ]\n",
      " [0.34647718]\n",
      " [0.13485754]\n",
      " [0.34647718]\n",
      " [0.46865818]\n",
      " [0.27724314]\n",
      " [0.9304199 ]\n",
      " [0.44063297]\n",
      " [0.24782537]\n",
      " [0.26000223]\n",
      " [0.9462127 ]\n",
      " [0.08645767]\n",
      " [0.90894526]\n",
      " [0.20627801]\n",
      " [0.40319416]\n",
      " [0.8929611 ]\n",
      " [0.27983797]\n",
      " [0.3866153 ]\n",
      " [0.2525775 ]\n",
      " [0.07505059]\n",
      " [0.34360054]\n",
      " [0.72887796]\n",
      " [0.31514528]\n",
      " [0.32013142]\n",
      " [0.61480325]\n",
      " [0.69800323]\n",
      " [0.34647718]\n",
      " [0.2679262 ]\n",
      " [0.46229976]\n",
      " [0.7846492 ]\n",
      " [0.8899378 ]\n",
      " [0.80210507]\n",
      " [0.49565738]\n",
      " [0.66613966]\n",
      " [0.11804652]\n",
      " [0.66273797]\n",
      " [0.34647718]\n",
      " [0.9680559 ]\n",
      " [0.5902964 ]\n",
      " [0.31993133]\n",
      " [0.53661466]\n",
      " [0.75561386]\n",
      " [0.17955376]\n",
      " [0.8077286 ]\n",
      " [0.6908093 ]\n",
      " [0.7467015 ]\n",
      " [0.23317644]\n",
      " [0.95261484]\n",
      " [0.15469341]\n",
      " [0.07502016]\n",
      " [0.5643277 ]\n",
      " [0.10877921]\n",
      " [0.04665934]\n",
      " [0.1948575 ]\n",
      " [0.24921371]\n",
      " [0.1004889 ]\n",
      " [0.5518554 ]\n",
      " [0.7459048 ]\n",
      " [0.28882694]\n",
      " [0.16985397]\n",
      " [0.34647718]\n",
      " [0.34647718]\n",
      " [0.38299292]\n",
      " [0.2033887 ]\n",
      " [0.4859537 ]\n",
      " [0.34647718]\n",
      " [0.34647718]\n",
      " [0.52666885]\n",
      " [0.43662027]\n",
      " [0.91118354]\n",
      " [0.19245517]\n",
      " [0.34647718]\n",
      " [0.76871276]\n",
      " [0.11804836]\n",
      " [0.3698384 ]\n",
      " [0.08936923]\n",
      " [0.21778108]\n",
      " [0.34647718]\n",
      " [0.10775412]\n",
      " [0.3917055 ]\n",
      " [0.34647718]\n",
      " [0.87452674]\n",
      " [0.4828295 ]\n",
      " [0.3217778 ]\n",
      " [0.10973633]\n",
      " [0.44744527]\n",
      " [0.10633493]\n",
      " [0.35216257]\n",
      " [0.37585688]\n",
      " [0.36251557]\n",
      " [0.37269387]\n",
      " [0.02667341]\n",
      " [0.9175143 ]\n",
      " [0.8281336 ]\n",
      " [0.34647718]\n",
      " [0.68335956]\n",
      " [0.13483244]\n",
      " [0.38299292]\n",
      " [0.12222424]\n",
      " [0.34647718]\n",
      " [0.16807282]\n",
      " [0.17826124]\n",
      " [0.78310734]\n",
      " [0.4247612 ]\n",
      " [0.09935055]\n",
      " [0.45303687]\n",
      " [0.949799  ]\n",
      " [0.5470891 ]\n",
      " [0.3256928 ]\n",
      " [0.7721749 ]\n",
      " [0.03997239]\n",
      " [0.50321203]\n",
      " [0.35976735]\n",
      " [0.12012907]\n",
      " [0.60421985]\n",
      " [0.34647718]\n",
      " [0.09900357]\n",
      " [0.34647718]\n",
      " [0.16496229]\n",
      " [0.26267448]\n",
      " [0.66658795]\n",
      " [0.34647718]\n",
      " [0.34647718]\n",
      " [0.8220464 ]\n",
      " [0.49393743]\n",
      " [0.95065236]\n",
      " [0.26081598]\n",
      " [0.34647718]\n",
      " [0.42208514]\n",
      " [0.07977958]\n",
      " [0.34647718]\n",
      " [0.11927597]\n",
      " [0.11615798]\n",
      " [0.6188098 ]\n",
      " [0.28725338]\n",
      " [0.5068724 ]\n",
      " [0.85582143]\n",
      " [0.6403517 ]\n",
      " [0.834021  ]\n",
      " [0.15249273]\n",
      " [0.34647718]\n",
      " [0.49048975]\n",
      " [0.02200003]\n",
      " [0.8743183 ]\n",
      " [0.8219629 ]\n",
      " [0.696404  ]\n",
      " [0.87081087]\n",
      " [0.44040546]\n",
      " [0.6030841 ]\n",
      " [0.34647718]\n",
      " [0.34647718]\n",
      " [0.34647718]\n",
      " [0.58525544]\n",
      " [0.27020094]\n",
      " [0.05075756]\n",
      " [0.15755329]\n",
      " [0.7922366 ]\n",
      " [0.7063721 ]\n",
      " [0.63956887]\n",
      " [0.34647718]\n",
      " [0.34647718]\n",
      " [0.09863841]\n",
      " [0.34647718]\n",
      " [0.11735696]\n",
      " [0.21395272]\n",
      " [0.19618659]\n",
      " [0.4719975 ]\n",
      " [0.0864315 ]\n",
      " [0.22864117]\n",
      " [0.43016827]\n",
      " [0.4841371 ]\n",
      " [0.61177576]\n",
      " [0.9100012 ]\n",
      " [0.88422495]\n",
      " [0.06768978]\n",
      " [0.04407673]\n",
      " [0.30867815]\n",
      " [0.2148976 ]\n",
      " [0.05429359]\n",
      " [0.34647718]\n",
      " [0.9310798 ]\n",
      " [0.34647718]\n",
      " [0.02027731]\n",
      " [0.59405416]\n",
      " [0.43650088]\n",
      " [0.34647718]\n",
      " [0.3467119 ]\n",
      " [0.34647718]\n",
      " [0.34647718]\n",
      " [0.17165075]\n",
      " [0.4014829 ]\n",
      " [0.21320516]\n",
      " [0.24691865]\n",
      " [0.7092126 ]\n",
      " [0.7216537 ]\n",
      " [0.8287188 ]\n",
      " [0.509328  ]\n",
      " [0.34647718]\n",
      " [0.7311503 ]\n",
      " [0.1620244 ]\n",
      " [0.37338832]\n",
      " [0.31302154]\n",
      " [0.5847887 ]\n",
      " [0.41027796]\n",
      " [0.14734787]\n",
      " [0.12602995]\n",
      " [0.34647718]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import pickle\n",
    "# values for confusion matrix\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # normalize the confusion matrix\n",
    "\n",
    "# values for ROC curve\n",
    "# Convert model output to probabilities and plot ROC curve\n",
    "y_pred_prob = model.predict(test_padded)\n",
    "print(y_pred_prob)\n",
    "fpr, tpr, thresholds = roc_curve(test_labels, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "\n",
    "# save the values to a file\n",
    "with open('2.3 CNN with fasttext existing model.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'fpr': fpr, 'tpr': tpr, 'roc_auc': roc_auc, 'cm_percentage': cm_percentage, 'report': report\n",
    "    }, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
